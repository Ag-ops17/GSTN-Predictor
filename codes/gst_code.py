# -*- coding: utf-8 -*-
"""GST_CODE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WUu1eLVr28QEn_lyQ_6SStmJdLIGLNUQ

#Loading Datasets
"""

!unzip /content/Train_60.zip
!unzip /content/Test_20.zip

"""#Data Preprocessing And Visualization"""

import pandas as pd
X_train, X_test, y_train, y_test = pd.read_csv('Train_60/Train_60/X_Train_Data_Input.csv'),pd.read_csv('Test_20/Test_20/X_Test_Data_Input.csv') , pd.read_csv('Train_60/Train_60/Y_Train_Data_Target.csv'), pd.read_csv('Test_20/Test_20/Y_Test_Data_Target.csv')

X_train.head()

y_train.head()

import pandas as pd

X_train = X_train.drop(X_train.columns[0], axis=1)
X_test = X_test.drop(X_test.columns[0], axis=1)
y_train = y_train.drop(y_train.columns[0], axis=1)
y_test = y_test.drop(y_test.columns[0], axis=1)

df_train=pd.concat([X_train, y_train], axis=1)
# Calculate correlation matrix
correlation_matrix = df_train.corr()

# Display the correlation with the target
correlation_with_target = correlation_matrix['target'].sort_values(ascending=False)
print("Correlation with target:\n", correlation_with_target)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Exclude the target column
correlation_with_target = correlation_with_target.drop('target')

plt.figure(figsize=(10, 6))
correlation_with_target.plot(kind='bar', color='pink')
plt.title('Feature Correlation with Target')
plt.xlabel('Features')
plt.ylabel('Correlation Coefficient')
plt.axhline(0, color='black', linewidth=0.8, linestyle='-')
plt.show()

#Check for duplicates between features and target
for column in X_train.columns:
    if X_train[column].equals(y_train.squeeze()):
        print(f"Potential leakage found in feature: {column}")

#Check for high variance or specific patterns in data
highly_correlated_features = correlation_with_target[correlation_with_target > 0.9].index.tolist()
if len(highly_correlated_features) > 0:
    print(f"Potentially leaked features (high correlation): {highly_correlated_features}")
else:
    print("No significant leakage detected based on correlation.")

#Check Null Values
X_train.isnull().sum()

#Drop Columns
columns_to_drop = ['Column9', 'Column14', 'Column21', 'Column20']

X_train = X_train.drop(columns=columns_to_drop)
X_test = X_test.drop(columns=columns_to_drop)

X_train = X_train.sample(n=500000, random_state=42)

X_train.shape

y_train = y_train.sample(n=500000, random_state=42)

y_train.shape

X_test = X_test.sample(n=100000, random_state=42)

X_test.shape

y_test = y_test.sample(n=100000, random_state=42)

y_test.shape

#Missing Values Handling
X_train = X_train.fillna(X_train.mean())
X_test = X_test.fillna(X_test.mean())

"""#Model Building And Result"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import PowerTransformer
from sklearn.preprocessing import StandardScaler
from scipy.ndimage import gaussian_filter

# Apply Standard Scaler to the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Apply power transform to the features
power_transformer = PowerTransformer()
X_transformed = power_transformer.fit_transform(X_train)
X_transformed_test = power_transformer.transform(X_test)

# Apply Gaussian filter to smooth the features
X_transformed = gaussian_filter(X_transformed, sigma=1)  # Adjust sigma for smoothing
X_transformed_test = gaussian_filter(X_transformed_test, sigma=1)

# Train the Random Forest classifier
random_forest_1 = RandomForestClassifier(random_state=42)
random_forest_1.fit(X_transformed, y_train)

# Extract the feature representations from the first Random Forest
rf_features = random_forest_1.apply(X_transformed_test)

# Reshape the RF features for input to KNN
rf_features = rf_features.reshape(rf_features.shape[0], -1)

# Build the KNN model
knn_model = KNeighborsClassifier(n_neighbors=5)

# Train the KNN model
knn_model.fit(rf_features, y_test)

# Make predictions using the KNN model
knn_predictions = knn_model.predict(rf_features)

# Combine the KNN predictions with the RF features
combined_features = np.concatenate((rf_features, knn_predictions.reshape(-1, 1)), axis=1)

# Train the second Random Forest classifier on the combined features
random_forest_2 = RandomForestClassifier(random_state=42)
random_forest_2.fit(combined_features, y_test)

# Make predictions using the second Random Forest
rf2_predictions = random_forest_2.predict(combined_features)

# Calculate the accuracy of the second Random Forest
accuracy = accuracy_score(y_test, rf2_predictions)
print("Accuracy:", accuracy)
predictions_df = pd.DataFrame({
    'KNN Predictions': knn_predictions.reshape(-1)
})
predictions_df1 = pd.DataFrame(rf_features)
predictions_df2 = pd.DataFrame({
    'RF2_Prediction': rf2_predictions
})

predictions_df.to_csv('knn_predictions.csv', index=False)
predictions_df1.to_csv('rf_features.csv', index=False)
predictions_df2.to_csv('rf2_predictions.csv', index=False)

